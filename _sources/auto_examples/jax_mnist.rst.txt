.. note::
    :class: sphx-glr-download-link-note

    Click :ref:`here <sphx_glr_download_auto_examples_jax_mnist.py>` to download the full example code
.. rst-class:: sphx-glr-example-title

.. _sphx_glr_auto_examples_jax_mnist.py:


Combining COPT with JAX
=======================

This example shows how JAX can be used within COPT
to compute the gradients of the objective function.
In this example tensorflow-datasets is used to provide
the training data.


.. code-block:: default

    import copt as cp
    import numpy as np
    import tensorflow_datasets as tfds
    from jax.experimental import stax
    from jax.experimental.stax import Dense, Relu, LogSoftmax


    def one_hot(x, k, dtype=np.float32):
      """Create a one-hot encoding of x of size k."""
      return np.array(x[:, None] == np.arange(k), dtype)

    data_dir = '/tmp/tfds'

    # Fetch full datasets for evaluation
    # tfds.load returns tf.Tensors (or tf.data.Datasets if batch_size != -1)
    # You can convert them to NumPy arrays (or iterables of NumPy arrays) with tfds.dataset_as_numpy
    mnist_data, info = tfds.load(name="mnist", batch_size=-1, data_dir=data_dir, with_info=True)
    mnist_data = tfds.as_numpy(mnist_data)
    train_data, test_data = mnist_data['train'], mnist_data['test']
    num_labels = info.features['label'].num_classes
    h, w, c = info.features['image'].shape
    num_pixels = h * w * c

    # Full train set
    train_images, train_labels = train_data['image'], train_data['label']
    train_images = np.reshape(train_images, (len(train_images), num_pixels))
    train_labels = one_hot(train_labels, num_labels)

    # Full test set
    test_images, test_labels = test_data['image'], test_data['label']
    test_images = np.reshape(test_images, (len(test_images), num_pixels))
    test_labels = one_hot(test_labels, num_labels)


    def loss(params, batch):
      inputs, targets = batch
      preds = predict(params, inputs)
      return -np.mean(preds * targets)

    def accuracy(params, batch):
      inputs, targets = batch
      target_class = np.argmax(targets, axis=1)
      predicted_class = np.argmax(predict(params, inputs), axis=1)
      return np.mean(predicted_class == target_class)

    init_random_params, predict = stax.serial(
        Dense(1024), Relu,
        Dense(1024), Relu,
        Dense(10), LogSoftmax)

    mnist_train = tfds.load(name="mnist", split=tfds.Split.TRAIN)

.. rst-class:: sphx-glr-timing

   **Total running time of the script:** ( 0 minutes  0.000 seconds)


.. _sphx_glr_download_auto_examples_jax_mnist.py:


.. only :: html

 .. container:: sphx-glr-footer
    :class: sphx-glr-footer-example



  .. container:: sphx-glr-download

     :download:`Download Python source code: jax_mnist.py <jax_mnist.py>`



  .. container:: sphx-glr-download

     :download:`Download Jupyter notebook: jax_mnist.ipynb <jax_mnist.ipynb>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
