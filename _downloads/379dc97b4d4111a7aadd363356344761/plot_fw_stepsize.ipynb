{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\nStep-size strategies for FW\n===========================\n\nPlot showing how an optimal step-size for the Frank-Wolfe algorithm\nevolves over time.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import matplotlib.pylab as plt\nfrom sklearn import datasets\nfrom scipy import optimize\nfrom scipy.sparse import linalg as splinalg\nimport numpy as np\nimport copt as cp\n\n# Construct a toy classification dataset with 100 samples and 10 features\nn_samples, n_features = 100, 10\nX, y = datasets.make_classification(n_samples, n_features, random_state=0)\n\n\n# Define an exact line search strategy\ndef exact_ls(kw):\n    def f_ls(gamma):\n        return kw['f_grad'](kw['x'] + gamma * kw['d_t'])[0]\n    ls_sol = optimize.minimize_scalar(f_ls, bounds=[0, 1], method='bounded')\n    return ls_sol.x\n\n\nl1_ball = cp.utils.L1Ball(n_features / 2.)\nf = cp.utils.LogLoss(X, y)\nx0 = np.zeros(n_features)\ntrace_step_size = []\ntrace_lipschitz = []\n\n\ndef cb(kw):\n    trace_step_size.append(kw['step_size'])\n    Hs = splinalg.LinearOperator(\n        shape=(n_features, n_features),\n        matvec=f.Hessian(kw['x']))\n\n    s, _ = splinalg.eigsh(Hs, k=1)\n    trace_lipschitz.append(s)\n\n\nout = cp.minimize_FW(\n    f.f_grad, l1_ball.lmo, x0, callback=cb, max_iter=1000,\n    backtracking=exact_ls, L=f.lipschitz)\n\n# Focus on the last 4/5, since the first iterations\n# tend to have a disproportionally large step-size\nn = len(trace_step_size) // 5\ntrace_step_size = trace_step_size[n:]\ntrace_lipschitz = trace_lipschitz[n:]\n\n\nfig, ax1 = plt.subplots()\n\ncolor = 'tab:red'\nax1.set_xlabel('number of iterations')\nax1.set_ylabel('step size', color=color)\nax1.plot(n + np.arange(len(trace_step_size)), trace_step_size, color=color, alpha=0.5)\nax1.tick_params(axis='y', labelcolor=color)\n\nax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\n\ncolor = 'tab:blue'\nax2.set_ylabel('Lipschitz constant', color=color)  # we already handled the x-label with ax1\nax2.plot(n + np.arange(len(trace_lipschitz)), trace_lipschitz, color=color)\nax2.tick_params(axis='y', labelcolor=color)\n\nfig.tight_layout()  # otherwise the right y-label is slightly clipped\nplt.grid()\nplt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}