{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\nFrank-Wolfe and Pairwise Frank-Wolfe\n====================================\n\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import numpy as np\nfrom scipy import sparse\nfrom scipy.sparse import linalg as splinalg\nimport pylab as plt\nimport copt as cp\n\nnp.random.seed(0)\n# \n# # .. generate some data ..\n# n_samples, n_features = 100, 100\n# \n# max_iter = 5000\n# print('#features', n_features)\n# \n# A = sparse.rand(n_samples, n_features, density=0.2)\n# sigma = 1.\n# b = A.dot(ground_truth) + sigma * np.random.randn(n_samples)\n# \n# np.random.seed(0)\n# n_samples = n_features\n# \n# # .. compute the step-size ..\n# s = splinalg.svds(A, k=1, return_singular_vectors=False,\n#                   tol=1e-3, maxiter=500)[0]\n# step_size = 1. / cp.utils.get_lipschitz(A, 'square')\n# f_grad = cp.utils.SquareLoss(A, b).f_grad\n# \n# # .. run the solver for different values ..\n# # .. of the regularization parameter beta ..\n# all_betas = [0, 1e-2, 1e-1, 0.2]\n# all_trace_ls, all_trace_nols, all_trace_pdhg_nols, all_trace_pdhg = [], [], [], []\n# all_trace_ls_time, all_trace_nols_time, all_trace_pdhg_nols_time, all_trace_pdhg_time = [], [], [], []\n# out_img = []\n# for i, beta in enumerate(all_betas):\n#     print('beta = %s' % beta)\n#     G1 = cp.utils.GroupL1(beta, blocks)\n# \n#     def loss(x):\n#         return f_grad(x)[0] + G1(x)\n# \n#     cb_tosls = cp.utils.Trace()\n#     x0 = np.zeros(n_features)\n#     cb_tosls(x0)\n#     pgd_ls = cp.minimize_PGD(\n#         f_grad, x0, G1.prox, step_size=step_size,\n#         max_iter=max_iter, tol=1e-14, verbose=1,\n#         callback=cb_tosls)\n#     trace_ls = np.array([loss(x) for x in cb_tosls.trace_x])\n#     all_trace_ls.append(trace_ls)\n#     all_trace_ls_time.append(cb_tosls.trace_time)\n# \n#     cb_tos = cp.utils.Trace()\n#     x0 = np.zeros(n_features)\n#     cb_tos(x0)\n#     pgd = cp.minimize_PGD(\n#         f_grad, x0, G1.prox,\n#         step_size=step_size,\n#         max_iter=max_iter, tol=1e-14, verbose=1,\n#         backtracking=False, callback=cb_tos)\n#     trace_nols = np.array([loss(x) for x in cb_tos.trace_x])\n#     all_trace_nols.append(trace_nols)\n#     all_trace_nols_time.append(cb_tos.trace_time)\n#     out_img.append(pgd.x)\n# \n# \n# # .. plot the results ..\n# fig, ax = plt.subplots(2, 4, sharey=False)\n# xlim = [0.02, 0.02, 0.1]\n# for i, beta in enumerate(all_betas):\n#     ax[0, i].set_title(r'$\\lambda=%s$' % beta)\n#     ax[0, i].set_title(r'$\\lambda=%s$' % beta)\n#     ax[0, i].plot(out_img[i])\n#     ax[0, i].plot(ground_truth)\n#     ax[0, i].set_ylim((-0.5, 1.5))\n#     ax[0, i].set_xticks(())\n#     ax[0, i].set_yticks(())\n# \n#     fmin = min(np.min(all_trace_ls[i]), np.min(all_trace_nols[i]))\n#     scale = all_trace_ls[i][0] - fmin\n#     plot_tos, = ax[1, i].plot(\n#         (all_trace_ls[i] - fmin) / scale,\n#         lw=4, marker='o', markevery=100,\n#         markersize=10)\n# \n#     plot_nols, = ax[1, i].plot(\n#         (all_trace_nols[i] - fmin) / scale,\n#         lw=4, marker='h', markevery=100,\n#         markersize=10)\n# \n#     ax[1, i].set_xlabel('Iterations')\n#     ax[1, i].set_yscale('log')\n#     ax[1, i].set_ylim((1e-14, None))\n#     ax[1, i].grid(True)\n# \n# \n# plt.gcf().subplots_adjust(bottom=0.15)\n# plt.figlegend(\n#     (plot_tos, plot_nols),\n#     ('PGD with line search', 'PGD without line search'), ncol=5,\n#     scatterpoints=1,\n#     loc=(-0.00, -0.0), frameon=False,\n#     bbox_to_anchor=[0.05, 0.01])\n# \n# ax[1, 0].set_ylabel('Objective minus optimum')\n# plt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}