{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\nCombining COPT with JAX\n=======================\n\nThis example shows how JAX can be used within COPT\nto compute the gradients of the objective function.\nIn this example tensorflow-datasets is used to provide\nthe training data.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import copt as cp\nimport numpy as np\nimport tensorflow_datasets as tfds\nfrom jax.experimental import stax\nfrom jax.experimental.stax import Dense, Relu, LogSoftmax\n\n\ndef one_hot(x, k, dtype=np.float32):\n  \"\"\"Create a one-hot encoding of x of size k.\"\"\"\n  return np.array(x[:, None] == np.arange(k), dtype)\n\ndata_dir = '/tmp/tfds'\n\n# Fetch full datasets for evaluation\n# tfds.load returns tf.Tensors (or tf.data.Datasets if batch_size != -1)\n# You can convert them to NumPy arrays (or iterables of NumPy arrays) with tfds.dataset_as_numpy\nmnist_data, info = tfds.load(name=\"mnist\", batch_size=-1, data_dir=data_dir, with_info=True)\nmnist_data = tfds.as_numpy(mnist_data)\ntrain_data, test_data = mnist_data['train'], mnist_data['test']\nnum_labels = info.features['label'].num_classes\nh, w, c = info.features['image'].shape\nnum_pixels = h * w * c\n\n# Full train set\ntrain_images, train_labels = train_data['image'], train_data['label']\ntrain_images = np.reshape(train_images, (len(train_images), num_pixels))\ntrain_labels = one_hot(train_labels, num_labels)\n\n# Full test set\ntest_images, test_labels = test_data['image'], test_data['label']\ntest_images = np.reshape(test_images, (len(test_images), num_pixels))\ntest_labels = one_hot(test_labels, num_labels)\n\n\ndef loss(params, batch):\n  inputs, targets = batch\n  preds = predict(params, inputs)\n  return -np.mean(preds * targets)\n\ndef accuracy(params, batch):\n  inputs, targets = batch\n  target_class = np.argmax(targets, axis=1)\n  predicted_class = np.argmax(predict(params, inputs), axis=1)\n  return np.mean(predicted_class == target_class)\n\ninit_random_params, predict = stax.serial(\n    Dense(1024), Relu,\n    Dense(1024), Relu,\n    Dense(10), LogSoftmax)\n\nmnist_train = tfds.load(name=\"mnist\", split=tfds.Split.TRAIN)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}