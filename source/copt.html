
<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta charset="utf-8" />
    <title>copt package &#8212; copt  documentation</title>
    <link rel="stylesheet" href="../_static/alabaster.css" type="text/css" />
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script type="text/javascript" src="../_static/jquery.js"></script>
    <script type="text/javascript" src="../_static/underscore.js"></script>
    <script type="text/javascript" src="../_static/doctools.js"></script>
    <script type="text/javascript" src="../_static/language_data.js"></script>
    <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.0/clipboard.min.js"></script>
    <script type="text/javascript" src="../_static/copybutton.js"></script>
    <script async="async" type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/x-mathjax-config">MathJax.Hub.Config({"TeX": {"Macros": {"argmin": "\\DeclareMathOperator*{\\argmin}{\\mathbf{arg\\,min}}", "argmax": "\\DeclareMathOperator*{\\argmin}{\\mathbf{arg\\,max}}", "bs": "\\newcommand{\\bs}[1]{\\boldsymbol{#1}}"}}})</script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
   
  <link rel="stylesheet" href="../_static/custom.css" type="text/css" />
  
  
  <meta name="viewport" content="width=device-width, initial-scale=0.9, maximum-scale=0.9" />

  </head><body>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          

          <div class="body" role="main">
            
  <div class="section" id="copt-package">
<h1>copt package<a class="headerlink" href="#copt-package" title="Permalink to this headline">¶</a></h1>
<div class="section" id="submodules">
<h2>Submodules<a class="headerlink" href="#submodules" title="Permalink to this headline">¶</a></h2>
</div>
<div class="section" id="module-copt.datasets">
<span id="copt-datasets-module"></span><h2>copt.datasets module<a class="headerlink" href="#module-copt.datasets" title="Permalink to this headline">¶</a></h2>
<dl class="function">
<dt id="copt.datasets.load_covtype">
<code class="sig-prename descclassname">copt.datasets.</code><code class="sig-name descname">load_covtype</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference external" href="https://github.com/openopt/copt/blob/74e01ee/copt/datasets.py#L196"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#copt.datasets.load_covtype" title="Permalink to this definition">¶</a></dt>
<dd><p>Download and return the covtype dataset.</p>
<p>This is the binary classification version of the dataset as found in the
LIBSVM dataset project:</p>
<blockquote>
<div><p><a class="reference external" href="https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/binary.html#covtype">https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/binary.html#covtype</a></p>
</div></blockquote>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p><ul class="simple">
<li><p><strong>X</strong> (<em>scipy.sparse CSR matrix</em>)</p></li>
<li><p><strong>y</strong> (<em>numpy array</em>) – Labels, only takes values 0 or 1.</p></li>
</ul>
</p>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="copt.datasets.load_criteo">
<code class="sig-prename descclassname">copt.datasets.</code><code class="sig-name descname">load_criteo</code><span class="sig-paren">(</span><em class="sig-param">md5_check=True</em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/openopt/copt/blob/74e01ee/copt/datasets.py#L352"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#copt.datasets.load_criteo" title="Permalink to this definition">¶</a></dt>
<dd><p>Download and return the criteo dataset.</p>
<p>This is the binary classification version of the dataset as found in the
LIBSVM dataset project:</p>
<blockquote>
<div><p><a class="reference external" href="https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/binary.html#criteo">https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/binary.html#criteo</a></p>
</div></blockquote>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>md5_check</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.7)"><em>bool</em></a>) – Whether to do an md5 check on the downloaded files.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>X</strong> (<em>scipy.sparse CSR matrix</em>)</p></li>
<li><p><strong>y</strong> (<em>numpy array</em>) – Labels, only takes values 0 or 1.</p></li>
</ul>
</p>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="copt.datasets.load_gisette">
<code class="sig-prename descclassname">copt.datasets.</code><code class="sig-name descname">load_gisette</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference external" href="https://github.com/openopt/copt/blob/74e01ee/copt/datasets.py#L225"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#copt.datasets.load_gisette" title="Permalink to this definition">¶</a></dt>
<dd><p>Download and return the covtype dataset.</p>
<p>This is the binary classification version of the dataset as found in the
LIBSVM dataset project:</p>
<blockquote>
<div><p><a class="reference external" href="https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/binary.html#gisette">https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/binary.html#gisette</a></p>
</div></blockquote>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p><p>scipy.sparse CSR matrix
y: numpy array</p>
<blockquote>
<div><p>Labels, only takes values 0 or 1.</p>
</div></blockquote>
</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>X</p>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="copt.datasets.load_img1">
<code class="sig-prename descclassname">copt.datasets.</code><code class="sig-name descname">load_img1</code><span class="sig-paren">(</span><em class="sig-param">n_rows=20</em>, <em class="sig-param">n_cols=20</em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/openopt/copt/blob/74e01ee/copt/datasets.py#L13"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#copt.datasets.load_img1" title="Permalink to this definition">¶</a></dt>
<dd><p>Load sample image.</p>
</dd></dl>

<dl class="function">
<dt id="copt.datasets.load_kdd10">
<code class="sig-prename descclassname">copt.datasets.</code><code class="sig-name descname">load_kdd10</code><span class="sig-paren">(</span><em class="sig-param">md5_check=True</em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/openopt/copt/blob/74e01ee/copt/datasets.py#L256"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#copt.datasets.load_kdd10" title="Permalink to this definition">¶</a></dt>
<dd><p>Download and return the KDD10 dataset.</p>
<p>This is the binary classification version of the dataset as found in the
LIBSVM dataset project:</p>
<blockquote>
<div><p><a class="reference external" href="https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/binary.html#kdd2010">https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/binary.html#kdd2010</a>
(bridge to algebra)</p>
</div></blockquote>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>md5_check</strong> – bool
Whether to do an md5 check on the downloaded files.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><p>scipy.sparse CSR matrix
y: numpy array</p>
<blockquote>
<div><p>Labels, only takes values 0 or 1.</p>
</div></blockquote>
</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>X</p>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="copt.datasets.load_kdd12">
<code class="sig-prename descclassname">copt.datasets.</code><code class="sig-name descname">load_kdd12</code><span class="sig-paren">(</span><em class="sig-param">md5_check=True</em>, <em class="sig-param">verbose=0</em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/openopt/copt/blob/74e01ee/copt/datasets.py#L293"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#copt.datasets.load_kdd12" title="Permalink to this definition">¶</a></dt>
<dd><p>Download and return the KDD12 dataset.</p>
<p>This is the binary classification version of the dataset as found in the
LIBSVM dataset project:</p>
<blockquote>
<div><p><a class="reference external" href="https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/binary.html#kdd2012">https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/binary.html#kdd2012</a></p>
</div></blockquote>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>md5_check</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.7)"><em>bool</em></a>) – Whether to do an md5 check on the downloaded files.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>X</strong> (<em>scipy.sparse CSR matrix</em>)</p></li>
<li><p><strong>y</strong> (<em>numpy array</em>) – Labels, only takes values 0 or 1.</p></li>
</ul>
</p>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="copt.datasets.load_madelon">
<code class="sig-prename descclassname">copt.datasets.</code><code class="sig-name descname">load_madelon</code><span class="sig-paren">(</span><em class="sig-param">md5_check=True</em>, <em class="sig-param">subset='full'</em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/openopt/copt/blob/74e01ee/copt/datasets.py#L22"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#copt.datasets.load_madelon" title="Permalink to this definition">¶</a></dt>
<dd><p>Download and return the madelon dataset.</p>
<dl class="simple">
<dt>Properties:</dt><dd><p>n_samples: 2600
n_features: 500</p>
</dd>
</dl>
<p>This is the binary classification version of the dataset as found in the
LIBSVM dataset project:</p>
<blockquote>
<div><p><a class="reference external" href="https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/binary.html#madelon">https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/binary.html#madelon</a></p>
</div></blockquote>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>md5_check</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.7)"><em>bool</em></a>) – Whether to do an md5 check on the downloaded files.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>X</strong> (<em>scipy.sparse CSR matrix, shape=(2600, 500)</em>)</p></li>
<li><p><strong>y</strong> (<em>numpy array</em>) – Labels, only takes values 0 or 1.</p></li>
</ul>
</p>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="copt.datasets.load_rcv1">
<code class="sig-prename descclassname">copt.datasets.</code><code class="sig-name descname">load_rcv1</code><span class="sig-paren">(</span><em class="sig-param">md5_check=True</em>, <em class="sig-param">subset='full'</em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/openopt/copt/blob/74e01ee/copt/datasets.py#L76"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#copt.datasets.load_rcv1" title="Permalink to this definition">¶</a></dt>
<dd><p>Download and return the RCV1 dataset.</p>
<p>This is the binary classification version of the dataset as found in the
LIBSVM dataset project:</p>
<blockquote>
<div><p><a class="reference external" href="https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/binary.html#rcv1.binary">https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/binary.html#rcv1.binary</a></p>
</div></blockquote>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>md5_check</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.7)"><em>bool</em></a>) – Whether to do an md5 check on the downloaded files.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>X</strong> (<em>scipy.sparse CSR matrix</em>)</p></li>
<li><p><strong>y</strong> (<em>numpy array</em>) – Labels, only takes values 0 or 1.</p></li>
</ul>
</p>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="copt.datasets.load_url">
<code class="sig-prename descclassname">copt.datasets.</code><code class="sig-name descname">load_url</code><span class="sig-paren">(</span><em class="sig-param">md5_check=True</em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/openopt/copt/blob/74e01ee/copt/datasets.py#L137"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#copt.datasets.load_url" title="Permalink to this definition">¶</a></dt>
<dd><p>Download and return the URL dataset.</p>
<p>This is the binary classification version of the dataset as found in the
LIBSVM dataset project:</p>
<blockquote>
<div><p><a class="reference external" href="https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/binary.html#url">https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/binary.html#url</a></p>
</div></blockquote>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>md5_check</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.7)"><em>bool</em></a>) – Whether to do an md5 check on the downloaded files.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>X</strong> (<em>scipy.sparse CSR matrix</em>)</p></li>
<li><p><strong>y</strong> (<em>numpy array</em>) – Labels, only takes values 0 or 1.</p></li>
</ul>
</p>
</dd>
</dl>
</dd></dl>

</div>
<div class="section" id="module-copt.frank_wolfe">
<span id="copt-frank-wolfe-module"></span><h2>copt.frank_wolfe module<a class="headerlink" href="#module-copt.frank_wolfe" title="Permalink to this headline">¶</a></h2>
<p>Frank-Wolfe and related algorithms.</p>
<dl class="attribute">
<dt id="copt.frank_wolfe.max_active">
<code class="sig-prename descclassname">copt.frank_wolfe.</code><code class="sig-name descname">max_active</code><a class="reference external" href="https://github.com/openopt/copt/blob/74e01ee/copt/frank_wolfe.py#L185"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#copt.frank_wolfe.max_active" title="Permalink to this definition">¶</a></dt>
<dd><p>Find the index that most correlates with the gradient.</p>
</dd></dl>

<dl class="function">
<dt id="copt.frank_wolfe.minimize_frank_wolfe">
<code class="sig-prename descclassname">copt.frank_wolfe.</code><code class="sig-name descname">minimize_frank_wolfe</code><span class="sig-paren">(</span><em class="sig-param">f_grad</em>, <em class="sig-param">x0</em>, <em class="sig-param">lmo</em>, <em class="sig-param">step_size=None</em>, <em class="sig-param">lipschitz=None</em>, <em class="sig-param">max_iter=200</em>, <em class="sig-param">tol=1e-12</em>, <em class="sig-param">callback=None</em>, <em class="sig-param">verbose=0</em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/openopt/copt/blob/74e01ee/copt/frank_wolfe.py#L11"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#copt.frank_wolfe.minimize_frank_wolfe" title="Permalink to this definition">¶</a></dt>
<dd><p>Frank-Wolfe algorithm.</p>
<p>This method for optimization problems of the form</p>
<div class="math notranslate nohighlight">
\[\argmin_{\bs{x} \in \mathcal{D}} f(\bs{x})\]</div>
<p>where f is a differentiable function for which we have access to its
gradient and D is a compact set for which we have access to its
linear minimization oracle (lmo), i.e., a routine that given a vector
<span class="math notranslate nohighlight">\(\bs{u}\)</span> returns a solution to</p>
<div class="math notranslate nohighlight">
\[\argmin_{\bs{x} \in D}\, \langle\bs{u}, \bs{x}\rangle\]</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>f_grad</strong> – callable
Takes as input the current iterate (a vector of same size as x0) and
returns the function value and gradient of the objective function.
It should accept the optional argument return_gradient, and when False
it should return only the function value.</p></li>
<li><p><strong>x0</strong> – array-like
Initial guess for solution.</p></li>
<li><p><strong>lmo</strong> – callable
Takes as input a vector u of same size as x0 and returns a solution to
the linear minimization oracle (defined above).</p></li>
<li><p><strong>step_size</strong> – None or “adaptive” or “adaptive2” or callable
Step-size step_size to use. If None is used and keyword lipschitz
is not given or None, then it will use a decreasing step-size of the
form 2/(k+1) (described in [1]). If None is used and keyword lipschitz
is not None, then it will use the Demyanov-Rubinov step-size step_size
(variant 1 in [2]).</p></li>
<li><p><strong>lipschitz</strong> – None or float.
Estimate for the Lipschitz constant of the gradient.</p></li>
<li><p><strong>max_iter</strong> – integer</p></li>
<li><p><strong>tol</strong> – float</p></li>
<li><p><strong>callback</strong> – callable</p></li>
<li><p><strong>verbose</strong> – int</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><dl class="simple">
<dt>scipy.optimize.OptimizeResult</dt><dd><p>The optimization result represented as a
<code class="docutils literal notranslate"><span class="pre">scipy.optimize.OptimizeResult</span></code> object. Important attributes are:
<code class="docutils literal notranslate"><span class="pre">x</span></code> the solution array, <code class="docutils literal notranslate"><span class="pre">success</span></code> a Boolean flag indicating if
the optimizer exited successfully and <code class="docutils literal notranslate"><span class="pre">message</span></code> which describes
the cause of the termination. See <cite>scipy.optimize.OptimizeResult</cite>
for a description of other attributes.</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>res</p>
</dd>
</dl>
<p class="rubric">References</p>
<p>[1] Jaggi, Martin. <a class="reference external" href="http://proceedings.mlr.press/v28/jaggi13-supp.pdf">“Revisiting Frank-Wolfe: Projection-Free Sparse Convex
Optimization.”</a> ICML
2013.</p>
<p>[2] Pedregosa, Fabian <a class="reference external" href="http://fa.bianp.net/blog/2018/notes-on-the-frank-wolfe-algorithm-part-i/">“Notes on the Frank-Wolfe Algorithm”</a>,
2018</p>
<p>[3] Pedregosa, Fabian, Armin Askari, Geoffrey Negiar, and Martin Jaggi.
<a class="reference external" href="https://arxiv.org/pdf/1806.05123.pdf">“Step-Size Adaptivity in Projection-Free Optimization.”</a> arXiv:1806.05123 (2018).</p>
</dd></dl>

<dl class="function">
<dt id="copt.frank_wolfe.minimize_pairwise_frank_wolfe_l1">
<code class="sig-prename descclassname">copt.frank_wolfe.</code><code class="sig-name descname">minimize_pairwise_frank_wolfe_l1</code><span class="sig-paren">(</span><em class="sig-param">f_grad</em>, <em class="sig-param">alpha</em>, <em class="sig-param">n_features</em>, <em class="sig-param">lipschitz=None</em>, <em class="sig-param">max_iter=1000</em>, <em class="sig-param">tol=1e-12</em>, <em class="sig-param">backtracking=True</em>, <em class="sig-param">callback=None</em>, <em class="sig-param">verbose=0</em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/openopt/copt/blob/74e01ee/copt/frank_wolfe.py#L207"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#copt.frank_wolfe.minimize_pairwise_frank_wolfe_l1" title="Permalink to this definition">¶</a></dt>
<dd><p>Pairwise FW on the L1 ball.</p>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>This feature is experimental, API is likely to change.</p>
</div>
</dd></dl>

</div>
<div class="section" id="module-copt.proximal_gradient">
<span id="copt-proximal-gradient-module"></span><h2>copt.proximal_gradient module<a class="headerlink" href="#module-copt.proximal_gradient" title="Permalink to this headline">¶</a></h2>
<p>Proximal-gradient algorithms.</p>
<dl class="function">
<dt id="copt.proximal_gradient.minimize_proximal_gradient">
<code class="sig-prename descclassname">copt.proximal_gradient.</code><code class="sig-name descname">minimize_proximal_gradient</code><span class="sig-paren">(</span><em class="sig-param">f_grad</em>, <em class="sig-param">x0</em>, <em class="sig-param">prox=None</em>, <em class="sig-param">tol=1e-06</em>, <em class="sig-param">max_iter=500</em>, <em class="sig-param">verbose=0</em>, <em class="sig-param">callback=None</em>, <em class="sig-param">step_size='adaptive'</em>, <em class="sig-param">accelerated=False</em>, <em class="sig-param">max_iter_backtracking=1000</em>, <em class="sig-param">backtracking_factor=0.6</em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/openopt/copt/blob/74e01ee/copt/proximal_gradient.py#L9"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#copt.proximal_gradient.minimize_proximal_gradient" title="Permalink to this definition">¶</a></dt>
<dd><p>Proximal gradient descent.</p>
<p>Solves problems of the form</p>
<blockquote>
<div><p>minimize_x f(x) + g(x)</p>
</div></blockquote>
<p>where we have access to the gradient of f and the proximal operator of g.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>f_grad</strong> – callable.
Value and gradient of f: <code class="docutils literal notranslate"><span class="pre">f_grad(x)</span> <span class="pre">-&gt;</span> <span class="pre">float,</span> <span class="pre">array-like</span></code>.</p></li>
<li><p><strong>x0</strong> – array-like of size n_features
Initial guess of solution.</p></li>
<li><p><strong>prox</strong> – callable, optional.
Proximal operator g.</p></li>
<li><p><strong>tol</strong> – float</p></li>
<li><p><strong>max_iter</strong> – int, optional.
Maximum number of iterations.</p></li>
<li><p><strong>verbose</strong> – int, optional.
Verbosity level, from 0 (no output) to 2 (output on each iteration)</p></li>
<li><p><strong>callback</strong> – callable.
callback function (optional). Takes a single argument (x) with the
current coefficients in the algorithm. The algorithm will exit if
callback returns False.</p></li>
<li><p><strong>step_size</strong> – float or “adaptive” or (float, “adaptive”).
Step-size value and/or strategy.</p></li>
<li><p><strong>accelerated</strong> – boolean
Whether to use the accelerated variant of the algorithm.</p></li>
<li><p><strong>max_iter_backtracking</strong> – int</p></li>
<li><p><strong>backtracking_factor</strong> – float</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><dl class="simple">
<dt>The optimization result represented as a</dt><dd><p><code class="docutils literal notranslate"><span class="pre">scipy.optimize.OptimizeResult</span></code> object. Important attributes are:
<code class="docutils literal notranslate"><span class="pre">x</span></code> the solution array, <code class="docutils literal notranslate"><span class="pre">success</span></code> a Boolean flag indicating if
the optimizer exited successfully and <code class="docutils literal notranslate"><span class="pre">message</span></code> which describes
the cause of the termination. See <cite>scipy.optimize.OptimizeResult</cite>
for a description of other attributes.</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>res</p>
</dd>
</dl>
<p class="rubric">References</p>
<p>Beck, Amir, and Marc Teboulle. “Gradient-based algorithms with applications
to signal recovery.” Convex optimization in signal processing and
communications (2009)</p>
<p class="rubric">Examples</p>
<ul class="simple">
<li><p><a class="reference internal" href="../auto_examples/plot_group_lasso.html#sphx-glr-auto-examples-plot-group-lasso-py"><span class="std std-ref">Group Lasso regularization</span></a></p></li>
</ul>
</dd></dl>

</div>
<div class="section" id="module-copt.randomized">
<span id="copt-randomized-module"></span><h2>copt.randomized module<a class="headerlink" href="#module-copt.randomized" title="Permalink to this headline">¶</a></h2>
<p>Module that contains randomized (also known as stochastic) algorithms.</p>
<dl class="function">
<dt id="copt.randomized.minimize_saga">
<code class="sig-prename descclassname">copt.randomized.</code><code class="sig-name descname">minimize_saga</code><span class="sig-paren">(</span><em class="sig-param">f_deriv</em>, <em class="sig-param">A</em>, <em class="sig-param">b</em>, <em class="sig-param">x0</em>, <em class="sig-param">step_size</em>, <em class="sig-param">prox=None</em>, <em class="sig-param">alpha=0</em>, <em class="sig-param">max_iter=500</em>, <em class="sig-param">tol=1e-06</em>, <em class="sig-param">verbose=1</em>, <em class="sig-param">callback=None</em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/openopt/copt/blob/74e01ee/copt/randomized.py#L61"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#copt.randomized.minimize_saga" title="Permalink to this definition">¶</a></dt>
<dd><p>Stochastic average gradient augmented (SAGA) algorithm.</p>
<p>This algorithm can solve linearly-parametrized loss functions of the form</p>
<blockquote>
<div><p>minimize_x sum_{i}^n_samples f(A_i^T x, b_i) + alpha ||x||_2^2 + g(x)</p>
</div></blockquote>
<p>where g is a function for which we have access to its proximal operator.</p>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>This function is experimental, API is likely to change.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>f</strong> – loss functions.</p></li>
<li><p><strong>x0</strong> (<em>np.ndarray</em><em> or </em><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.7)"><em>None</em></a><em>, </em><em>optional</em>) – Starting point for optimization.</p></li>
<li><p><strong>step_size</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.7)"><em>float</em></a><em> or </em><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.7)"><em>None</em></a><em>, </em><em>optional</em>) – Step size for the optimization. If None is given, this will be
estimated from the function f.</p></li>
<li><p><strong>max_iter</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a>) – Maximum number of passes through the data in the optimization.</p></li>
<li><p><strong>tol</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.7)"><em>float</em></a>) – Tolerance criterion. The algorithm will stop whenever the norm of the
gradient mapping (generalization of the gradient for nonsmooth
optimization) is below tol.</p></li>
<li><p><strong>verbose</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.7)"><em>bool</em></a>) – Verbosity level. True might print some messages.</p></li>
<li><p><strong>trace</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.7)"><em>bool</em></a>) – Whether to trace convergence of the function, useful for plotting
and/or debugging. If ye, the result will have extra members trace_func,
trace_time.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>opt</strong> – The optimization result represented as a
<code class="docutils literal notranslate"><span class="pre">scipy.optimize.OptimizeResult</span></code> object. Important attributes are:
<code class="docutils literal notranslate"><span class="pre">x</span></code> the solution array, <code class="docutils literal notranslate"><span class="pre">success</span></code> a Boolean flag indicating if
the optimizer exited successfully and <code class="docutils literal notranslate"><span class="pre">message</span></code> which describes
the cause of the termination. See <cite>scipy.optimize.OptimizeResult</cite>
for a description of other attributes.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>OptimizeResult</p>
</dd>
</dl>
<p class="rubric">References</p>
<p>This variant of the SAGA algorithm is described in:</p>
<p><a class="reference external" href="https://arxiv.org/pdf/1707.06468.pdf">“Breaking the Nonsmooth Barrier: A Scalable Parallel Method for Composite
Optimization.”</a>, Fabian Pedregosa, Remi Leblond,
and Simon Lacoste-Julien. Advances in Neural Information Processing Systems
(NIPS) 2017.</p>
</dd></dl>

<dl class="function">
<dt id="copt.randomized.minimize_svrg">
<code class="sig-prename descclassname">copt.randomized.</code><code class="sig-name descname">minimize_svrg</code><span class="sig-paren">(</span><em class="sig-param">f_deriv</em>, <em class="sig-param">A</em>, <em class="sig-param">b</em>, <em class="sig-param">x0</em>, <em class="sig-param">step_size</em>, <em class="sig-param">alpha=0</em>, <em class="sig-param">prox=None</em>, <em class="sig-param">max_iter=500</em>, <em class="sig-param">tol=1e-06</em>, <em class="sig-param">verbose=False</em>, <em class="sig-param">callback=None</em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/openopt/copt/blob/74e01ee/copt/randomized.py#L235"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#copt.randomized.minimize_svrg" title="Permalink to this definition">¶</a></dt>
<dd><p>Stochastic average gradient augmented (SAGA) algorithm.</p>
<p>The SAGA algorithm can solve optimization problems of the form</p>
<blockquote>
<div><p>argmin_{x in R^p} sum_{i}^n_samples f(A_i^T x, b_i) + alpha *
||x||_2^2 +</p>
<blockquote>
<div><ul class="simple">
<li><p>beta * ||x||_1</p></li>
</ul>
</div></blockquote>
</div></blockquote>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>f_deriv</strong> – derivative of f</p></li>
<li><p><strong>x0</strong> (<em>np.ndarray</em><em> or </em><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.7)"><em>None</em></a><em>, </em><em>optional</em>) – Starting point for optimization.</p></li>
<li><p><strong>step_size</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.7)"><em>float</em></a><em> or </em><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.7)"><em>None</em></a><em>, </em><em>optional</em>) – Step size for the optimization. If None is given, this will be
estimated from the function f.</p></li>
<li><p><strong>n_jobs</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a>) – Number of threads to use in the optimization. A number higher than 1
will use the Asynchronous SAGA optimization method described in
[Pedregosa et al., 2017]</p></li>
<li><p><strong>max_iter</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a>) – Maximum number of passes through the data in the optimization.</p></li>
<li><p><strong>tol</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.7)"><em>float</em></a>) – Tolerance criterion. The algorithm will stop whenever the norm of the
gradient mapping (generalization of the gradient for nonsmooth
optimization)
is below tol.</p></li>
<li><p><strong>verbose</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.7)"><em>bool</em></a>) – Verbosity level. True might print some messages.</p></li>
<li><p><strong>trace</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.7)"><em>bool</em></a>) – Whether to trace convergence of the function, useful for plotting and/or
debugging. If ye, the result will have extra members trace_func,
trace_time.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>opt</strong> – The optimization result represented as a
<code class="docutils literal notranslate"><span class="pre">scipy.optimize.OptimizeResult</span></code> object. Important attributes are:
<code class="docutils literal notranslate"><span class="pre">x</span></code> the solution array, <code class="docutils literal notranslate"><span class="pre">success</span></code> a Boolean flag indicating if
the optimizer exited successfully and <code class="docutils literal notranslate"><span class="pre">message</span></code> which describes
the cause of the termination. See <cite>scipy.optimize.OptimizeResult</cite>
for a description of other attributes.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>OptimizeResult</p>
</dd>
</dl>
<p class="rubric">References</p>
<p>The SAGA algorithm was originally described in</p>
<p>Aaron Defazio, Francis Bach, and Simon Lacoste-Julien. <a class="reference external" href="https://arxiv.org/abs/1407.0202">SAGA: A fast
incremental gradient method with support for non-strongly convex composite
objectives.</a> Advances in Neural
Information Processing Systems. 2014.</p>
<p>The implemented has some improvements with respect to the original,
like support for sparse datasets and is described in</p>
<p>Fabian Pedregosa, Remi Leblond, and Simon Lacoste-Julien.
“Breaking the Nonsmooth Barrier: A Scalable Parallel Method
for Composite Optimization.” Advances in Neural Information
Processing Systems (NIPS) 2017.</p>
</dd></dl>

<dl class="function">
<dt id="copt.randomized.minimize_vrtos">
<code class="sig-prename descclassname">copt.randomized.</code><code class="sig-name descname">minimize_vrtos</code><span class="sig-paren">(</span><em class="sig-param">f_deriv</em>, <em class="sig-param">A</em>, <em class="sig-param">b</em>, <em class="sig-param">x0</em>, <em class="sig-param">step_size</em>, <em class="sig-param">prox_1=None</em>, <em class="sig-param">prox_2=None</em>, <em class="sig-param">alpha=0</em>, <em class="sig-param">max_iter=500</em>, <em class="sig-param">tol=1e-06</em>, <em class="sig-param">callback=None</em>, <em class="sig-param">verbose=0</em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/openopt/copt/blob/74e01ee/copt/randomized.py#L420"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#copt.randomized.minimize_vrtos" title="Permalink to this definition">¶</a></dt>
<dd><p>Variance-reduced three operator splitting (VRTOS) algorithm.</p>
<p>The VRTOS algorithm can solve optimization problems of the form</p>
<blockquote>
<div><p>argmin_{x in R^p} sum_{i}^n_samples f(A_i^T x, b_i) + alpha *
||x||_2^2 +</p>
<blockquote>
<div><ul class="simple">
<li><p>pen1(x) + pen2(x)</p></li>
</ul>
</div></blockquote>
</div></blockquote>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>f_deriv</strong> – derivative of f</p></li>
<li><p><strong>x0</strong> (<em>np.ndarray</em><em> or </em><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.7)"><em>None</em></a><em>, </em><em>optional</em>) – Starting point for optimization.</p></li>
<li><p><strong>step_size</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.7)"><em>float</em></a><em> or </em><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.7)"><em>None</em></a><em>, </em><em>optional</em>) – Step size for the optimization. If None is given, this will be
estimated from the function f.</p></li>
<li><p><strong>n_jobs</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a>) – Number of threads to use in the optimization. A number higher than 1
will use the Asynchronous SAGA optimization method described in
[Pedregosa et al., 2017]</p></li>
<li><p><strong>max_iter</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a>) – Maximum number of passes through the data in the optimization.</p></li>
<li><p><strong>tol</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.7)"><em>float</em></a>) – Tolerance criterion. The algorithm will stop whenever the norm of the
gradient mapping (generalization of the gradient for nonsmooth
optimization)
is below tol.</p></li>
<li><p><strong>verbose</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.7)"><em>bool</em></a>) – Verbosity level. True might print some messages.</p></li>
<li><p><strong>trace</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.7)"><em>bool</em></a>) – Whether to trace convergence of the function, useful for plotting and/or
debugging. If ye, the result will have extra members trace_func,
trace_time.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>opt</strong> – The optimization result represented as a
<code class="docutils literal notranslate"><span class="pre">scipy.optimize.OptimizeResult</span></code> object. Important attributes are:
<code class="docutils literal notranslate"><span class="pre">x</span></code> the solution array, <code class="docutils literal notranslate"><span class="pre">success</span></code> a Boolean flag indicating if
the optimizer exited successfully and <code class="docutils literal notranslate"><span class="pre">message</span></code> which describes
the cause of the termination. See <cite>scipy.optimize.OptimizeResult</cite>
for a description of other attributes.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>OptimizeResult</p>
</dd>
</dl>
<p class="rubric">References</p>
<p>Pedregosa, Fabian, Kilian Fatras, and Mattia Casotto. “Variance Reduced
Three Operator Splitting.” arXiv preprint arXiv:1806.07294 (2018).</p>
</dd></dl>

</div>
<div class="section" id="module-copt.splitting">
<span id="copt-splitting-module"></span><h2>copt.splitting module<a class="headerlink" href="#module-copt.splitting" title="Permalink to this headline">¶</a></h2>
<dl class="function">
<dt id="copt.splitting.minimize_primal_dual">
<code class="sig-prename descclassname">copt.splitting.</code><code class="sig-name descname">minimize_primal_dual</code><span class="sig-paren">(</span><em class="sig-param">f_grad</em>, <em class="sig-param">x0</em>, <em class="sig-param">prox_1=None</em>, <em class="sig-param">prox_2=None</em>, <em class="sig-param">L=None</em>, <em class="sig-param">tol=1e-12</em>, <em class="sig-param">max_iter=1000</em>, <em class="sig-param">callback=None</em>, <em class="sig-param">step_size=1.0</em>, <em class="sig-param">step_size2=None</em>, <em class="sig-param">line_search=True</em>, <em class="sig-param">max_iter_ls=20</em>, <em class="sig-param">verbose=0</em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/openopt/copt/blob/74e01ee/copt/splitting.py#L166"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#copt.splitting.minimize_primal_dual" title="Permalink to this definition">¶</a></dt>
<dd><p>Primal-dual hybrid gradient splitting method.</p>
<p>This method for optimization problems of the form</p>
<blockquote>
<div><p>minimize_x f(x) + alpha * g(x) + beta * h(L x)</p>
</div></blockquote>
<p>where f is a smooth function and g is a (possibly non-smooth)
function for which the proximal operator is known.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>f_grad</strong> (<em>callable</em>) – Returns the function value and gradient of the objective function.
It should accept the optional argument return_gradient, and when False
it should return only the function value.</p></li>
<li><p><strong>prox_1</strong> (<em>callable of the form prox_1</em><em>(</em><em>x</em><em>, </em><em>alpha</em><em>)</em>) – prox_1(x, alpha) returns the proximal operator of g at x
with parameter alpha.</p></li>
<li><p><strong>x0</strong> (<em>array-like</em>) – Initial guess of solution.</p></li>
<li><p><strong>L</strong> (<em>ndarray</em><em> or </em><em>sparse matrix</em>) – Linear operator inside the h term.</p></li>
<li><p><strong>max_iter</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a>) – Maximum number of iterations.</p></li>
<li><p><strong>verbose</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a>) – Verbosity level, from 0 (no output) to 2 (output on each iteration)</p></li>
<li><p><strong>callback</strong> (<em>callable.</em>) – callback function (optional). Takes a single argument (x) with the
current coefficients in the algorithm. The algorithm will exit if
callback returns False.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>res</strong> – The optimization result represented as a
<code class="docutils literal notranslate"><span class="pre">scipy.optimize.OptimizeResult</span></code> object. Important attributes are:
<code class="docutils literal notranslate"><span class="pre">x</span></code> the solution array, <code class="docutils literal notranslate"><span class="pre">success</span></code> a Boolean flag indicating if
the optimizer exited successfully and <code class="docutils literal notranslate"><span class="pre">message</span></code> which describes
the cause of the termination. See <cite>scipy.optimize.OptimizeResult</cite>
for a description of other attributes.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>OptimizeResult</p>
</dd>
</dl>
<p class="rubric">References</p>
<p>Condat, Laurent. “A primal-dual splitting method for convex optimization
involving Lipschitzian, proximable and linear composite terms.” Journal of
Optimization Theory and Applications (2013).</p>
<p>Chambolle, Antonin, and Thomas Pock. “On the ergodic convergence rates of a
first-order primal-dual algorithm.” Mathematical Programming (2015)</p>
</dd></dl>

<dl class="function">
<dt id="copt.splitting.minimize_three_split">
<code class="sig-prename descclassname">copt.splitting.</code><code class="sig-name descname">minimize_three_split</code><span class="sig-paren">(</span><em class="sig-param">f_grad</em>, <em class="sig-param">x0</em>, <em class="sig-param">prox_1=None</em>, <em class="sig-param">prox_2=None</em>, <em class="sig-param">tol=1e-06</em>, <em class="sig-param">max_iter=1000</em>, <em class="sig-param">verbose=0</em>, <em class="sig-param">callback=None</em>, <em class="sig-param">line_search=True</em>, <em class="sig-param">step_size=None</em>, <em class="sig-param">max_iter_backtracking=100</em>, <em class="sig-param">backtracking_factor=0.7</em>, <em class="sig-param">h_Lipschitz=None</em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/openopt/copt/blob/74e01ee/copt/splitting.py#L9"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#copt.splitting.minimize_three_split" title="Permalink to this definition">¶</a></dt>
<dd><p>Davis-Yin three operator splitting method.</p>
<p>This algorithm can solve problems of the form</p>
<blockquote>
<div><p>minimize_x f(x) + g(x) + h(x)</p>
</div></blockquote>
<p>where f is a smooth function and g is a (possibly non-smooth)
function for which the proximal operator is known.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>f_grad</strong> (<em>callable</em>) – Returns the function value and gradient of the objective function.
With return_gradient=False, returns only the function value.</p></li>
<li><p><strong>prox_1</strong> (<em>callable</em><em> or </em><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.7)"><em>None</em></a>) – prox_1(x, alpha, <a href="#id1"><span class="problematic" id="id2">*</span></a>args) returns the proximal operator of g at xa
with parameter alpha. Extra arguments can be passed by prox_1_args.</p></li>
<li><p><strong>y0</strong> (<em>array-like</em>) – Initial guess</p></li>
<li><p><strong>backtracking</strong> (<em>boolean</em>) – Whether to perform backtracking (i.e. line-search) to estimate
the step size.</p></li>
<li><p><strong>max_iter</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a>) – Maximum number of iterations.</p></li>
<li><p><strong>verbose</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a>) – Verbosity level, from 0 (no output) to 2 (output on each iteration)</p></li>
<li><p><strong>step_size</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.7)"><em>float</em></a>) – Starting value for the line-search procedure.</p></li>
<li><p><strong>callback</strong> (<em>callable.</em>) – callback function (optional). Takes a single argument (x) with the
current coefficients in the algorithm. The algorithm will exit if
callback returns False.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>res</strong> – The optimization result represented as a
<code class="docutils literal notranslate"><span class="pre">scipy.optimize.OptimizeResult</span></code> object. Important attributes are:
<code class="docutils literal notranslate"><span class="pre">x</span></code> the solution array, <code class="docutils literal notranslate"><span class="pre">success</span></code> a Boolean flag indicating if
the optimizer exited successfully and <code class="docutils literal notranslate"><span class="pre">message</span></code> which describes
the cause of the termination. See <cite>scipy.optimize.OptimizeResult</cite>
for a description of other attributes.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>OptimizeResult</p>
</dd>
</dl>
<p class="rubric">References</p>
<ul class="simple">
<li><p>Davis, Damek, and Wotao Yin. <a href="#id3"><span class="problematic" id="id4">`</span></a>”A three-operator splitting scheme and its</p></li>
</ul>
<dl class="simple">
<dt>optimization</dt><dd><p>applications.” &lt;<a class="reference external" href="https://doi.org/10.1007/s11228-017-0421-z">https://doi.org/10.1007/s11228-017-0421-z</a>&gt;`_ Set-Valued
and Variational Analysis, 2017.</p>
</dd>
</dl>
<ul class="simple">
<li><p>Pedregosa, Fabian, and Gauthier Gidel. <a href="#id5"><span class="problematic" id="id6">`</span></a>”Adaptive Three Operator</p></li>
</ul>
<dl class="simple">
<dt>Splitting.”</dt><dd><p>&lt;<a class="reference external" href="https://arxiv.org/abs/1804.02339">https://arxiv.org/abs/1804.02339</a>&gt;`_ Proceedings of the 35th International
Conference
on Machine Learning, 2018.</p>
</dd>
</dl>
</dd></dl>

</div>
<div class="section" id="module-copt.tv_prox">
<span id="copt-tv-prox-module"></span><h2>copt.tv_prox module<a class="headerlink" href="#module-copt.tv_prox" title="Permalink to this headline">¶</a></h2>
<p>These are implementations of some proximal operators</p>
<dl class="function">
<dt id="copt.tv_prox.c_prox_tv2d">
<code class="sig-prename descclassname">copt.tv_prox.</code><code class="sig-name descname">c_prox_tv2d</code><span class="sig-paren">(</span><em class="sig-param">step_size</em>, <em class="sig-param">x</em>, <em class="sig-param">n_rows</em>, <em class="sig-param">n_cols</em>, <em class="sig-param">max_iter</em>, <em class="sig-param">tol</em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/openopt/copt/blob/74e01ee/copt/tv_prox.py#L147"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#copt.tv_prox.c_prox_tv2d" title="Permalink to this definition">¶</a></dt>
<dd><p>Proximal Dykstra to minimize a 2-dimensional total variation.</p>
<p>Reference: Algorithm 7 in <a class="reference external" href="https://arxiv.org/abs/1411.0589">https://arxiv.org/abs/1411.0589</a></p>
</dd></dl>

<dl class="function">
<dt id="copt.tv_prox.prox_tv1d">
<code class="sig-prename descclassname">copt.tv_prox.</code><code class="sig-name descname">prox_tv1d</code><span class="sig-paren">(</span><em class="sig-param">w</em>, <em class="sig-param">step_size</em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/openopt/copt/blob/74e01ee/copt/tv_prox.py#L14"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#copt.tv_prox.prox_tv1d" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes the proximal operator of the 1-dimensional total variation operator.</p>
<p>This solves a problem of the form</p>
<blockquote>
<div><p>argmin_x TV(x) + (1/(2 stepsize)) ||x - w||^2</p>
</div></blockquote>
<p>where TV(x) is the one-dimensional total variation</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>w</strong> (<em>array</em>) – vector of coefficients</p></li>
<li><p><strong>step_size</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.7)"><em>float</em></a>) – step size (sometimes denoted gamma) in proximal objective function</p></li>
</ul>
</dd>
</dl>
<p class="rubric">References</p>
<p>Condat, Laurent. “A direct algorithm for 1D total variation denoising.”
IEEE Signal Processing Letters (2013)</p>
</dd></dl>

<dl class="attribute">
<dt id="copt.tv_prox.prox_tv1d_cols">
<code class="sig-prename descclassname">copt.tv_prox.</code><code class="sig-name descname">prox_tv1d_cols</code><a class="reference external" href="https://github.com/openopt/copt/blob/74e01ee/copt/tv_prox.py#L125"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#copt.tv_prox.prox_tv1d_cols" title="Permalink to this definition">¶</a></dt>
<dd><p>apply prox_tv1d along columns of the matri a</p>
</dd></dl>

<dl class="attribute">
<dt id="copt.tv_prox.prox_tv1d_rows">
<code class="sig-prename descclassname">copt.tv_prox.</code><code class="sig-name descname">prox_tv1d_rows</code><a class="reference external" href="https://github.com/openopt/copt/blob/74e01ee/copt/tv_prox.py#L136"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#copt.tv_prox.prox_tv1d_rows" title="Permalink to this definition">¶</a></dt>
<dd><p>apply prox_tv1d along rows of the matri a</p>
</dd></dl>

<dl class="function">
<dt id="copt.tv_prox.prox_tv2d">
<code class="sig-prename descclassname">copt.tv_prox.</code><code class="sig-name descname">prox_tv2d</code><span class="sig-paren">(</span><em class="sig-param">w</em>, <em class="sig-param">step_size</em>, <em class="sig-param">n_rows</em>, <em class="sig-param">n_cols</em>, <em class="sig-param">max_iter=500</em>, <em class="sig-param">tol=1e-06</em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/openopt/copt/blob/74e01ee/copt/tv_prox.py#L175"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#copt.tv_prox.prox_tv2d" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes the proximal operator of the 2-dimensional total variation operator.</p>
<p>This solves a problem of the form</p>
<blockquote>
<div><p>argmin_x TV(x) + (1/(2 stepsize)) ||x - w||^2</p>
</div></blockquote>
<p>where TV(x) is the two-dimensional total variation. It does so using the
Douglas-Rachford algorithm [Barbero and Sra, 2014].</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>w</strong> (<em>array</em>) – vector of coefficients</p></li>
<li><p><strong>step_size</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.7)"><em>float</em></a>) – step size (often denoted gamma) in proximal objective function</p></li>
<li><p><strong>max_iter</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a>) – </p></li>
<li><p><strong>tol</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.7)"><em>float</em></a>) – </p></li>
</ul>
</dd>
</dl>
<p class="rubric">References</p>
<p>Condat, Laurent. “A direct algorithm for 1D total variation denoising.”
IEEE Signal Processing Letters (2013)</p>
<p>Barbero, Alvaro, and Suvrit Sra. “Modular proximal optimization for
multidimensional total-variation regularization.” arXiv preprint
arXiv:1411.0589 (2014).</p>
</dd></dl>

<dl class="function">
<dt id="copt.tv_prox.tv2d_linear_operator">
<code class="sig-prename descclassname">copt.tv_prox.</code><code class="sig-name descname">tv2d_linear_operator</code><span class="sig-paren">(</span><em class="sig-param">n_rows</em>, <em class="sig-param">n_cols</em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/openopt/copt/blob/74e01ee/copt/tv_prox.py#L212"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#copt.tv_prox.tv2d_linear_operator" title="Permalink to this definition">¶</a></dt>
<dd><p>Return the linear operator L such ||L x||_1 is the 2D total variation norm.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>n_rows</strong> – </p></li>
<li><p><strong>n_cols</strong> – </p></li>
</ul>
</dd>
</dl>
</dd></dl>

</div>
<div class="section" id="module-copt.utils">
<span id="copt-utils-module"></span><h2>copt.utils module<a class="headerlink" href="#module-copt.utils" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="copt.utils.FusedLasso">
<em class="property">class </em><code class="sig-prename descclassname">copt.utils.</code><code class="sig-name descname">FusedLasso</code><span class="sig-paren">(</span><em class="sig-param">alpha</em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/openopt/copt/blob/74e01ee/copt/utils.py#L483"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#copt.utils.FusedLasso" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference external" href="https://docs.python.org/3/library/functions.html#object" title="(in Python v3.7)"><code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></a></p>
<p>Fused Lasso penalty</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>alpha</strong> (<em>scalar</em>) – </p>
</dd>
</dl>
<p class="rubric">Examples</p>
<dl class="method">
<dt id="copt.utils.FusedLasso.prox">
<code class="sig-name descname">prox</code><span class="sig-paren">(</span><em class="sig-param">x</em>, <em class="sig-param">step_size</em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/openopt/copt/blob/74e01ee/copt/utils.py#L501"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#copt.utils.FusedLasso.prox" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="copt.utils.FusedLasso.prox_1_factory">
<code class="sig-name descname">prox_1_factory</code><span class="sig-paren">(</span><em class="sig-param">n_features</em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/openopt/copt/blob/74e01ee/copt/utils.py#L506"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#copt.utils.FusedLasso.prox_1_factory" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="copt.utils.FusedLasso.prox_2_factory">
<code class="sig-name descname">prox_2_factory</code><span class="sig-paren">(</span><em class="sig-param">n_features</em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/openopt/copt/blob/74e01ee/copt/utils.py#L540"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#copt.utils.FusedLasso.prox_2_factory" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt id="copt.utils.GroupL1">
<em class="property">class </em><code class="sig-prename descclassname">copt.utils.</code><code class="sig-name descname">GroupL1</code><span class="sig-paren">(</span><em class="sig-param">alpha</em>, <em class="sig-param">groups</em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/openopt/copt/blob/74e01ee/copt/utils.py#L392"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#copt.utils.GroupL1" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference external" href="https://docs.python.org/3/library/functions.html#object" title="(in Python v3.7)"><code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></a></p>
<p>Group Lasso penalty</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>alpha</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.7)"><em>float</em></a>) – Constat multiplying this loss</p></li>
<li><p><strong>blocks</strong> (<em>list of lists</em>) – </p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="copt.utils.GroupL1.prox">
<code class="sig-name descname">prox</code><span class="sig-paren">(</span><em class="sig-param">x</em>, <em class="sig-param">step_size</em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/openopt/copt/blob/74e01ee/copt/utils.py#L419"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#copt.utils.GroupL1.prox" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="copt.utils.GroupL1.prox_factory">
<code class="sig-name descname">prox_factory</code><span class="sig-paren">(</span><em class="sig-param">n_features</em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/openopt/copt/blob/74e01ee/copt/utils.py#L430"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#copt.utils.GroupL1.prox_factory" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt id="copt.utils.HuberLoss">
<em class="property">class </em><code class="sig-prename descclassname">copt.utils.</code><code class="sig-name descname">HuberLoss</code><span class="sig-paren">(</span><em class="sig-param">A</em>, <em class="sig-param">b</em>, <em class="sig-param">alpha=0</em>, <em class="sig-param">delta=1</em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/openopt/copt/blob/74e01ee/copt/utils.py#L294"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#copt.utils.HuberLoss" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference external" href="https://docs.python.org/3/library/functions.html#object" title="(in Python v3.7)"><code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></a></p>
<p>Huber loss</p>
<dl class="method">
<dt id="copt.utils.HuberLoss.f_grad">
<code class="sig-name descname">f_grad</code><span class="sig-paren">(</span><em class="sig-param">x</em>, <em class="sig-param">return_gradient=True</em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/openopt/copt/blob/74e01ee/copt/utils.py#L306"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#copt.utils.HuberLoss.f_grad" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="copt.utils.HuberLoss.lipschitz">
<em class="property">property </em><code class="sig-name descname">lipschitz</code><a class="headerlink" href="#copt.utils.HuberLoss.lipschitz" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt id="copt.utils.L1Ball">
<em class="property">class </em><code class="sig-prename descclassname">copt.utils.</code><code class="sig-name descname">L1Ball</code><span class="sig-paren">(</span><em class="sig-param">alpha</em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/openopt/copt/blob/74e01ee/copt/utils.py#L361"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#copt.utils.L1Ball" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference external" href="https://docs.python.org/3/library/functions.html#object" title="(in Python v3.7)"><code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></a></p>
<p>Indicator function over the L1 ball</p>
<p>This function is 0 if the sum of absolute values is less than or equal to
alpha, and infinity otherwise.</p>
<dl class="method">
<dt id="copt.utils.L1Ball.lmo">
<code class="sig-name descname">lmo</code><span class="sig-paren">(</span><em class="sig-param">u</em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/openopt/copt/blob/74e01ee/copt/utils.py#L379"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#copt.utils.L1Ball.lmo" title="Permalink to this definition">¶</a></dt>
<dd><p>Solve the linear problem
min_{||s||_1 &lt;= alpha} &lt;u, s&gt;</p>
</dd></dl>

<dl class="method">
<dt id="copt.utils.L1Ball.prox">
<code class="sig-name descname">prox</code><span class="sig-paren">(</span><em class="sig-param">x</em>, <em class="sig-param">step_size</em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/openopt/copt/blob/74e01ee/copt/utils.py#L376"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#copt.utils.L1Ball.prox" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt id="copt.utils.L1Norm">
<em class="property">class </em><code class="sig-prename descclassname">copt.utils.</code><code class="sig-name descname">L1Norm</code><span class="sig-paren">(</span><em class="sig-param">alpha</em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/openopt/copt/blob/74e01ee/copt/utils.py#L325"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#copt.utils.L1Norm" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference external" href="https://docs.python.org/3/library/functions.html#object" title="(in Python v3.7)"><code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></a></p>
<p>L1 norm, that is, the sum of absolute values:</p>
<div class="math notranslate nohighlight">
\[\alpha\sum_i^d |x_i|\]</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>alpha</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.7)"><em>float</em></a>) – constant multiplying the L1 norm</p>
</dd>
</dl>
<dl class="method">
<dt id="copt.utils.L1Norm.prox">
<code class="sig-name descname">prox</code><span class="sig-paren">(</span><em class="sig-param">x</em>, <em class="sig-param">step_size</em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/openopt/copt/blob/74e01ee/copt/utils.py#L344"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#copt.utils.L1Norm.prox" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="copt.utils.L1Norm.prox_factory">
<code class="sig-name descname">prox_factory</code><span class="sig-paren">(</span><em class="sig-param">n_features</em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/openopt/copt/blob/74e01ee/copt/utils.py#L348"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#copt.utils.L1Norm.prox_factory" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt id="copt.utils.LogLoss">
<em class="property">class </em><code class="sig-prename descclassname">copt.utils.</code><code class="sig-name descname">LogLoss</code><span class="sig-paren">(</span><em class="sig-param">A</em>, <em class="sig-param">b</em>, <em class="sig-param">alpha=0.0</em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/openopt/copt/blob/74e01ee/copt/utils.py#L123"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#copt.utils.LogLoss" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference external" href="https://docs.python.org/3/library/functions.html#object" title="(in Python v3.7)"><code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></a></p>
<p>A class evaluation and derivatives of the logistic loss. The logistic loss function is defined as</p>
<div class="math notranslate nohighlight">
\[-\frac{1}{n}\sum_{i=1}^n b_i \log(\sigma(\bs{a}_i^T \bs{x})) + (1 - b_i) \log(1 - \sigma(\bs{a}_i^T \bs{x}))\]</div>
<p>where <span class="math notranslate nohighlight">\(\sigma\)</span> is the sigmoid function <span class="math notranslate nohighlight">\(\sigma(t) = 1/(1 + e^{-t})\)</span></p>
<p>The input vector b verifies <span class="math notranslate nohighlight">\(0 \leq b_i \leq 1\)</span>. When it comes from
class labels, it should have the values 0 or 1.</p>
<p class="rubric">References</p>
<p><a class="reference external" href="http://fa.bianp.net/drafts/derivatives_logistic.html">http://fa.bianp.net/drafts/derivatives_logistic.html</a></p>
<dl class="method">
<dt id="copt.utils.LogLoss.Hessian">
<code class="sig-name descname">Hessian</code><span class="sig-paren">(</span><em class="sig-param">x</em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/openopt/copt/blob/74e01ee/copt/utils.py#L188"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#copt.utils.LogLoss.Hessian" title="Permalink to this definition">¶</a></dt>
<dd><p>Return a callable that performs dot products with the Hessian</p>
</dd></dl>

<dl class="method">
<dt id="copt.utils.LogLoss.f_grad">
<code class="sig-name descname">f_grad</code><span class="sig-paren">(</span><em class="sig-param">x</em>, <em class="sig-param">return_gradient=True</em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/openopt/copt/blob/74e01ee/copt/utils.py#L162"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#copt.utils.LogLoss.f_grad" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="copt.utils.LogLoss.lipschitz">
<em class="property">property </em><code class="sig-name descname">lipschitz</code><a class="headerlink" href="#copt.utils.LogLoss.lipschitz" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="copt.utils.LogLoss.max_lipschitz">
<em class="property">property </em><code class="sig-name descname">max_lipschitz</code><a class="headerlink" href="#copt.utils.LogLoss.max_lipschitz" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="copt.utils.LogLoss.partial_deriv">
<em class="property">property </em><code class="sig-name descname">partial_deriv</code><a class="headerlink" href="#copt.utils.LogLoss.partial_deriv" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt id="copt.utils.SimplexConstraint">
<em class="property">class </em><code class="sig-prename descclassname">copt.utils.</code><code class="sig-name descname">SimplexConstraint</code><span class="sig-paren">(</span><em class="sig-param">s=1</em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/openopt/copt/blob/74e01ee/copt/utils.py#L576"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#copt.utils.SimplexConstraint" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference external" href="https://docs.python.org/3/library/functions.html#object" title="(in Python v3.7)"><code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></a></p>
<dl class="method">
<dt id="copt.utils.SimplexConstraint.prox">
<code class="sig-name descname">prox</code><span class="sig-paren">(</span><em class="sig-param">x</em>, <em class="sig-param">step_size</em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/openopt/copt/blob/74e01ee/copt/utils.py#L580"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#copt.utils.SimplexConstraint.prox" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt id="copt.utils.SquareLoss">
<em class="property">class </em><code class="sig-prename descclassname">copt.utils.</code><code class="sig-name descname">SquareLoss</code><span class="sig-paren">(</span><em class="sig-param">A</em>, <em class="sig-param">b</em>, <em class="sig-param">alpha=0</em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/openopt/copt/blob/74e01ee/copt/utils.py#L258"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#copt.utils.SquareLoss" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference external" href="https://docs.python.org/3/library/functions.html#object" title="(in Python v3.7)"><code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></a></p>
<p>A class evaluation and derivatives of the square loss, defined as</p>
<blockquote>
<div><div class="math notranslate nohighlight">
\[\frac{1}{n}\|A x - b\|^2~,\]</div>
</div></blockquote>
<p>where <span class="math notranslate nohighlight">\(\|\cdot\|\)</span> is the euclidean norm.</p>
<dl class="method">
<dt id="copt.utils.SquareLoss.f_grad">
<code class="sig-name descname">f_grad</code><span class="sig-paren">(</span><em class="sig-param">x</em>, <em class="sig-param">return_gradient=True</em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/openopt/copt/blob/74e01ee/copt/utils.py#L280"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#copt.utils.SquareLoss.f_grad" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="copt.utils.SquareLoss.lipschitz">
<em class="property">property </em><code class="sig-name descname">lipschitz</code><a class="headerlink" href="#copt.utils.SquareLoss.lipschitz" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt id="copt.utils.TotalVariation2D">
<em class="property">class </em><code class="sig-prename descclassname">copt.utils.</code><code class="sig-name descname">TotalVariation2D</code><span class="sig-paren">(</span><em class="sig-param">alpha</em>, <em class="sig-param">shape</em>, <em class="sig-param">max_iter=100</em>, <em class="sig-param">tol=1e-06</em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/openopt/copt/blob/74e01ee/copt/utils.py#L721"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#copt.utils.TotalVariation2D" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference external" href="https://docs.python.org/3/library/functions.html#object" title="(in Python v3.7)"><code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></a></p>
<p>2-dimensional Total Variation pseudo-norm</p>
<dl class="method">
<dt id="copt.utils.TotalVariation2D.prox">
<code class="sig-name descname">prox</code><span class="sig-paren">(</span><em class="sig-param">x</em>, <em class="sig-param">step_size</em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/openopt/copt/blob/74e01ee/copt/utils.py#L737"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#copt.utils.TotalVariation2D.prox" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt id="copt.utils.Trace">
<em class="property">class </em><code class="sig-prename descclassname">copt.utils.</code><code class="sig-name descname">Trace</code><span class="sig-paren">(</span><em class="sig-param">f=None</em>, <em class="sig-param">freq=1</em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/openopt/copt/blob/74e01ee/copt/utils.py#L61"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#copt.utils.Trace" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference external" href="https://docs.python.org/3/library/functions.html#object" title="(in Python v3.7)"><code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></a></p>
</dd></dl>

<dl class="class">
<dt id="copt.utils.TraceBall">
<em class="property">class </em><code class="sig-prename descclassname">copt.utils.</code><code class="sig-name descname">TraceBall</code><span class="sig-paren">(</span><em class="sig-param">alpha</em>, <em class="sig-param">shape</em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/openopt/copt/blob/74e01ee/copt/utils.py#L689"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#copt.utils.TraceBall" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference external" href="https://docs.python.org/3/library/functions.html#object" title="(in Python v3.7)"><code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></a></p>
<p>Projection onto the trace (aka nuclear) norm, sum of singular values</p>
<dl class="attribute">
<dt id="copt.utils.TraceBall.is_separable">
<code class="sig-name descname">is_separable</code><em class="property"> = False</em><a class="headerlink" href="#copt.utils.TraceBall.is_separable" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="copt.utils.TraceBall.lmo">
<code class="sig-name descname">lmo</code><span class="sig-paren">(</span><em class="sig-param">x</em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/openopt/copt/blob/74e01ee/copt/utils.py#L714"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#copt.utils.TraceBall.lmo" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="copt.utils.TraceBall.prox">
<code class="sig-name descname">prox</code><span class="sig-paren">(</span><em class="sig-param">x</em>, <em class="sig-param">step_size</em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/openopt/copt/blob/74e01ee/copt/utils.py#L705"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#copt.utils.TraceBall.prox" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="copt.utils.TraceBall.prox_factory">
<code class="sig-name descname">prox_factory</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference external" href="https://github.com/openopt/copt/blob/74e01ee/copt/utils.py#L711"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#copt.utils.TraceBall.prox_factory" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt id="copt.utils.TraceNorm">
<em class="property">class </em><code class="sig-prename descclassname">copt.utils.</code><code class="sig-name descname">TraceNorm</code><span class="sig-paren">(</span><em class="sig-param">alpha</em>, <em class="sig-param">shape</em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/openopt/copt/blob/74e01ee/copt/utils.py#L665"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#copt.utils.TraceNorm" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference external" href="https://docs.python.org/3/library/functions.html#object" title="(in Python v3.7)"><code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></a></p>
<p>Trace (aka nuclear) norm, sum of singular values</p>
<dl class="attribute">
<dt id="copt.utils.TraceNorm.is_separable">
<code class="sig-name descname">is_separable</code><em class="property"> = False</em><a class="headerlink" href="#copt.utils.TraceNorm.is_separable" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="copt.utils.TraceNorm.prox">
<code class="sig-name descname">prox</code><span class="sig-paren">(</span><em class="sig-param">x</em>, <em class="sig-param">step_size</em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/openopt/copt/blob/74e01ee/copt/utils.py#L678"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#copt.utils.TraceNorm.prox" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="copt.utils.TraceNorm.prox_factory">
<code class="sig-name descname">prox_factory</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference external" href="https://github.com/openopt/copt/blob/74e01ee/copt/utils.py#L685"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#copt.utils.TraceNorm.prox_factory" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="function">
<dt id="copt.utils.euclidean_proj_l1ball">
<code class="sig-prename descclassname">copt.utils.</code><code class="sig-name descname">euclidean_proj_l1ball</code><span class="sig-paren">(</span><em class="sig-param">v</em>, <em class="sig-param">s=1</em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/openopt/copt/blob/74e01ee/copt/utils.py#L628"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#copt.utils.euclidean_proj_l1ball" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute the Euclidean projection on a L1-ball
Solves the optimisation problem (using the algorithm from [1]):</p>
<blockquote>
<div><p>min_w 0.5 * || w - v ||_2^2 , s.t. || w ||_1 &lt;= s</p>
</div></blockquote>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>v</strong> (<em>(</em><em>n</em><em>,</em><em>) </em><em>numpy array</em><em>,</em>) – n-dimensional vector to project</p></li>
<li><p><strong>s</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.7)"><em>float</em></a><em>, </em><em>optional</em><em>, </em><em>default: 1</em><em>,</em>) – radius of the L1-ball</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>w</strong> – Euclidean projection of v on the L1-ball of radius s</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>(n,) numpy array,</p>
</dd>
</dl>
<p class="rubric">Notes</p>
<p>Solves the problem by a reduction to the positive simplex case</p>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<p><a class="reference internal" href="#copt.utils.euclidean_proj_simplex" title="copt.utils.euclidean_proj_simplex"><code class="xref py py-func docutils literal notranslate"><span class="pre">euclidean_proj_simplex()</span></code></a></p>
</div>
</dd></dl>

<dl class="function">
<dt id="copt.utils.euclidean_proj_simplex">
<code class="sig-prename descclassname">copt.utils.</code><code class="sig-name descname">euclidean_proj_simplex</code><span class="sig-paren">(</span><em class="sig-param">v</em>, <em class="sig-param">s=1.0</em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/openopt/copt/blob/74e01ee/copt/utils.py#L584"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#copt.utils.euclidean_proj_simplex" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute the Euclidean projection on a positive simplex
Solves the optimisation problem (using the algorithm from [1]):</p>
<blockquote>
<div><p>min_w 0.5 * || w - v ||_2^2 , s.t. sum_i w_i = s, w_i &gt;= 0</p>
</div></blockquote>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>v</strong> (<em>(</em><em>n</em><em>,</em><em>) </em><em>numpy array</em><em>,</em>) – n-dimensional vector to project</p></li>
<li><p><strong>s</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.7)"><em>float</em></a><em>, </em><em>optional</em><em>, </em><em>default: 1</em><em>,</em>) – radius of the simplex</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>w</strong> – Euclidean projection of v on the simplex</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>(n,) numpy array,</p>
</dd>
</dl>
<p class="rubric">Notes</p>
<p>The complexity of this algorithm is in O(n log(n)) as it involves sorting v.
Better alternatives exist for high-dimensional sparse vectors (cf. [1])
However, this implementation still easily scales to millions of dimensions.</p>
<p class="rubric">References</p>
<dl class="simple">
<dt>[1] Efficient Projections onto the .1-Ball for Learning in High Dimensions</dt><dd><p>John Duchi, Shai Shalev-Shwartz, Yoram Singer, and Tushar Chandra.
International Conference on Machine Learning (ICML 2008)
<a class="reference external" href="http://www.cs.berkeley.edu/~jduchi/projects/DuchiSiShCh08.pdf">http://www.cs.berkeley.edu/~jduchi/projects/DuchiSiShCh08.pdf</a></p>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="copt.utils.get_max_lipschitz">
<code class="sig-prename descclassname">copt.utils.</code><code class="sig-name descname">get_max_lipschitz</code><span class="sig-paren">(</span><em class="sig-param">A</em>, <em class="sig-param">loss</em>, <em class="sig-param">alpha=0</em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/openopt/copt/blob/74e01ee/copt/utils.py#L102"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#copt.utils.get_max_lipschitz" title="Permalink to this definition">¶</a></dt>
<dd><p>XXX DEPRECATED</p>
<p>Estimate the max Lipschitz constant (as appears in
many stochastic methods).</p>
<p>A : array-like</p>
<p>loss : {“logloss”, “square”, “huber”}</p>
</dd></dl>

<dl class="function">
<dt id="copt.utils.init_lipschitz">
<code class="sig-prename descclassname">copt.utils.</code><code class="sig-name descname">init_lipschitz</code><span class="sig-paren">(</span><em class="sig-param">f_grad</em>, <em class="sig-param">x0</em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/openopt/copt/blob/74e01ee/copt/utils.py#L84"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#copt.utils.init_lipschitz" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="copt.utils.parse_step_size">
<code class="sig-prename descclassname">copt.utils.</code><code class="sig-name descname">parse_step_size</code><span class="sig-paren">(</span><em class="sig-param">step_size</em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/openopt/copt/blob/74e01ee/copt/utils.py#L49"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#copt.utils.parse_step_size" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="copt.utils.safe_sparse_add">
<code class="sig-prename descclassname">copt.utils.</code><code class="sig-name descname">safe_sparse_add</code><span class="sig-paren">(</span><em class="sig-param">a</em>, <em class="sig-param">b</em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/openopt/copt/blob/74e01ee/copt/utils.py#L31"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#copt.utils.safe_sparse_add" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</div>
<div class="section" id="module-copt">
<span id="module-contents"></span><h2>Module contents<a class="headerlink" href="#module-copt" title="Permalink to this headline">¶</a></h2>
<p>COPT: composite optimization in Python.</p>
</div>
</div>


          </div>
          
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
            <p class="logo"><a href="../index.html">
              <img class="logo" src="../_static/logo.png" alt="Logo"/>
            </a></p>
<h1 class="logo"><a href="../index.html">copt</a></h1>



<p class="blurb">Optimization in Python</p>




<p>
<iframe src="https://ghbtns.com/github-btn.html?user=openopt&repo=copt&type=watch&count=true&size=large&v=2"
  allowtransparency="true" frameborder="0" scrolling="0" width="200px" height="35px"></iframe>
</p>





    

<p>
<a class="badge" href="https://travis-ci.org/openopt/copt">
    <img
        alt="https://secure.travis-ci.org/openopt/copt.svg?branch=master"
        src="https://secure.travis-ci.org/openopt/copt.svg?branch=master"
    />
</a>
</p>


<h3>Navigation</h3>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../proximal_gradient.html">Gradient-based methods</a></li>
<li class="toctree-l1"><a class="reference internal" href="../proximal_splitting.html">Proximal splitting</a></li>
<li class="toctree-l1"><a class="reference internal" href="../frank_wolfe.html">Frank-Wolfe and other projection-free algorithms</a></li>
<li class="toctree-l1"><a class="reference internal" href="../incremental.html">Incremental methods</a></li>
<li class="toctree-l1"><a class="reference internal" href="../loss_functions.html">Loss functions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../auto_examples/index.html">Examples</a></li>
<li class="toctree-l1"><a class="reference internal" href="../datasets.html">Datasets</a></li>
</ul>


<div id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="../search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" />
      <input type="submit" value="Go" />
    </form>
    </div>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &copy;COPT developers.
      
      |
      Powered by <a href="http://sphinx-doc.org/">Sphinx 2.1.2</a>
      &amp; <a href="https://github.com/bitprophet/alabaster">Alabaster 0.7.12</a>
      
      |
      <a href="../_sources/source/copt.rst.txt"
          rel="nofollow">Page source</a>
    </div>

    

    
  </body>
</html>